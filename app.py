import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image
import io
import base64
from typing import List
import time
import os
import warnings
import torch

# ê²½ê³  ë©”ì‹œì§€ ë° ë¡œê·¸ ìµœì†Œí™”
warnings.filterwarnings('ignore')
os.environ['YOLO_VERBOSE'] = 'False'

# ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ´ ì”ë°˜ íƒì§€ê¸°",
    page_icon="ğŸ´",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# YOLO ëª¨ë¸ ë¡œë“œ (ì¼ê´€ì„±ì„ ìœ„í•œ ìˆ˜ì •)
@st.cache_resource(show_spinner=True)
def load_model():
    """YOLO ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìºì‹œì— ì €ì¥ - Gradioì™€ ë™ì¼í•œ ì„¤ì •"""
    try:
        with st.spinner("ğŸ¤– AI ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            model = YOLO('best.pt')
            
            # Gradioì™€ ë™ì¼í•œ ì„¤ì • ì ìš©
            model.to('cpu')  # ë˜ëŠ” 'cuda' - Gradioì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•˜ê²Œ
            
            # ëª¨ë¸ì˜ NMS ì„¤ì •ì„ ê³ ì • (Gradioì™€ ë™ì¼í•˜ê²Œ)
            model.overrides['iou'] = 0.45  # IoU threshold
            model.overrides['agnostic_nms'] = False
            model.overrides['max_det'] = 300
            
            # ì›Œë°ì—… ì—†ì´ ë°”ë¡œ ë°˜í™˜ (ì¼ê´€ì„±ì„ ìœ„í•´)
            
        return model, "âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ"
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None, f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"

# ê°ì²´ ê°ì§€ í•¨ìˆ˜ (ì¼ê´€ì„±ì„ ìœ„í•œ ëŒ€í­ ìˆ˜ì •)
def detect_objects_consistent(image_bytes, confidence_threshold=0.5):
    """Gradioì™€ ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•œ ê°ì²´ ê°ì§€ í•¨ìˆ˜"""
    model, status = load_model()
    
    if model is None:
        return None, [], status
    
    try:
        # bytesë¥¼ PIL Imageë¡œ ë³€í™˜ (Gradioì™€ ë™ì¼í•œ ë°©ì‹)
        image = Image.open(io.BytesIO(image_bytes))
        if image.mode != "RGB":
            image = image.convert("RGB")
        
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        img_array = np.array(image)
        
        # â˜… ì¤‘ìš”: ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•ì„ Gradioì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        # ë§Œì•½ Gradioì—ì„œ íŠ¹ì • í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì§•í•œë‹¤ë©´ ì—¬ê¸°ì„œë„ ë™ì¼í•˜ê²Œ
        original_height, original_width = img_array.shape[:2]
        
        # Gradioì—ì„œ ì‚¬ìš©í•˜ëŠ” ì „ì²˜ë¦¬ì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤
        # ì˜ˆ: 640x640ìœ¼ë¡œ íŒ¨ë”©ì´ë‚˜ ë¦¬ì‚¬ì´ì§•ì„ í•œë‹¤ë©´
        # img_array = letterbox_resize(img_array, (640, 640))
        
        # YOLO ì¶”ë¡  - Gradioì™€ ì •í™•íˆ ë™ì¼í•œ íŒŒë¼ë¯¸í„° ì‚¬ìš©
        results = model(
            img_array, 
            conf=confidence_threshold,
            iou=0.45,  # IoU threshold ëª…ì‹œì  ì„¤ì •
            verbose=False,
            save=False,
            save_txt=False,
            save_conf=False,
            augment=False,  # ë°ì´í„° ì¦ê°• ë¹„í™œì„±í™” (ì¼ê´€ì„±ì„ ìœ„í•´)
            agnostic_nms=False,
            max_det=300,
            device='cpu'  # Gradioì™€ ë™ì¼í•œ ë””ë°”ì´ìŠ¤
        )
        
        # ê²°ê³¼ ì²˜ë¦¬ - Gradioì™€ ë™ì¼í•œ ë°©ì‹
        detections = []
        annotated_image = img_array.copy()
        
        # Gradioì™€ ë™ì¼í•œ ìƒ‰ìƒ ì‚¬ìš© (ê³ ì •ëœ ìƒ‰ìƒ)
        colors = [
            (0, 255, 0),    # ë…¹ìƒ‰
            (255, 0, 0),    # ë¹¨ê°„ìƒ‰  
            (0, 0, 255),    # íŒŒë€ìƒ‰
            (255, 255, 0),  # ë…¸ë€ìƒ‰
            (255, 0, 255),  # ë§ˆì  íƒ€
            (0, 255, 255),  # ì‹œì•ˆ
            (128, 0, 128),  # ë³´ë¼ìƒ‰
            (255, 165, 0),  # ì£¼í™©ìƒ‰
        ]
        
        for result in results:
            if result.boxes is not None:
                # ë°•ìŠ¤ë“¤ì„ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ ìˆœì„œ ë³´ì¥
                boxes_data = []
                for box in result.boxes:
                    x1, y1, x2, y2 = map(float, box.xyxy[0].cpu().numpy())
                    class_id = int(box.cls[0].cpu().numpy())
                    confidence = float(box.conf[0].cpu().numpy())
                    boxes_data.append((x1, y1, x2, y2, class_id, confidence))
                
                # ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì¼ê´€ëœ ìˆœì„œë¥¼ ìœ„í•´)
                boxes_data.sort(key=lambda x: (x[1], x[0]))  # yì¢Œí‘œ, xì¢Œí‘œ ìˆœ
                
                for i, (x1, y1, x2, y2, class_id, confidence) in enumerate(boxes_data):
                    if confidence >= confidence_threshold:
                        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                        class_name = model.names[class_id]
                        
                        # í´ë˜ìŠ¤ë³„ ê³ ì • ìƒ‰ìƒ (Gradioì™€ ë™ì¼)
                        color = colors[class_id % len(colors)]
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (Gradioì™€ ë™ì¼í•œ ìŠ¤íƒ€ì¼)
                        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)
                        
                        # ë¼ë²¨ ê·¸ë¦¬ê¸° (Gradioì™€ ë™ì¼í•œ ë°©ì‹)
                        label = f"{class_name} {confidence:.2f}"
                        font_scale = 0.7
                        thickness = 2
                        
                        (label_width, label_height), baseline = cv2.getTextSize(
                            label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness
                        )
                        
                        # ë¼ë²¨ ë°°ê²½
                        cv2.rectangle(
                            annotated_image,
                            (x1, y1 - label_height - baseline - 5),
                            (x1 + label_width + 5, y1),
                            color,
                            -1
                        )
                        
                        # ë¼ë²¨ í…ìŠ¤íŠ¸
                        cv2.putText(
                            annotated_image,
                            label,
                            (x1 + 2, y1 - baseline - 2),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            font_scale,
                            (255, 255, 255),
                            thickness
                        )
                        
                        # ê°ì§€ ê²°ê³¼ ì €ì¥
                        detections.append({
                            "class_name": class_name,
                            "confidence": confidence,
                            "bbox": [x1, y1, x2, y2],
                            "area": (x2 - x1) * (y2 - y1),
                            "class_id": class_id
                        })
        
        return Image.fromarray(annotated_image), detections, "âœ… ê°ì§€ ì™„ë£Œ"
        
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None, [], f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def letterbox_resize(img, new_shape=(640, 640), color=(114, 114, 114)):
    """
    YOLOì—ì„œ ì‚¬ìš©í•˜ëŠ” letterbox ë¦¬ì‚¬ì´ì§• (Gradioì™€ ë™ì¼í•œ ì „ì²˜ë¦¬)
    ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ íŒ¨ë”©ìœ¼ë¡œ í¬ê¸° ì¡°ì •
    """
    shape = img.shape[:2]  # í˜„ì¬ í¬ê¸° [height, width]
    
    # ìŠ¤ì¼€ì¼ ë¹„ìœ¨ ê³„ì‚°
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    
    # ìƒˆë¡œìš´ í¬ê¸° ê³„ì‚°
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # íŒ¨ë”©
    
    # íŒ¨ë”©ì„ ì–‘ìª½ì— ê· ë“±í•˜ê²Œ ë¶„ë°°
    dw /= 2
    dh /= 2
    
    if shape[::-1] != new_unpad:  # ë¦¬ì‚¬ì´ì¦ˆ í•„ìš”
        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
    
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
    
    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return img

# ìºì‹± ì œê±°ëœ ê°ì§€ í•¨ìˆ˜ (ë§¤ë²ˆ ìƒˆë¡œ ì‹¤í–‰)
def detect_objects_no_cache(image_bytes, confidence_threshold=0.5):
    """ìºì‹± ì—†ì´ ë§¤ë²ˆ ìƒˆë¡œ ì¶”ë¡ í•˜ëŠ” í•¨ìˆ˜"""
    return detect_objects_consistent(image_bytes, confidence_threshold)

# ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ì€ ë™ì¼...
def get_confidence_color_class(confidence):
    """ì •í™•ë„ì— ë”°ë¥¸ CSS í´ë˜ìŠ¤ ë°˜í™˜"""
    if confidence >= 0.8:
        return "confidence-high"
    elif confidence >= 0.5:
        return "confidence-medium"
    else:
        return "confidence-low"

def display_detection_stats(detections):
    """ê°ì§€ í†µê³„ë¥¼ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ"""
    if not detections:
        return
    
    # í´ë˜ìŠ¤ë³„ í†µê³„ ê³„ì‚°
    class_counts = {}
    total_area = 0
    
    for det in detections:
        class_name = det['class_name']
        class_counts[class_name] = class_counts.get(class_name, 0) + 1
        total_area += det['area']
    
    # í†µê³„ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“Š ì´ ê°ì²´", len(detections))
    
    with col2:
        st.metric("ğŸ·ï¸ í´ë˜ìŠ¤ ìˆ˜", len(class_counts))
    
    with col3:
        avg_conf = sum(det['confidence'] for det in detections) / len(detections)
        st.metric("ğŸ¯ í‰ê·  ì •í™•ë„", f"{avg_conf:.1%}")
    
    with col4:
        max_conf = max(det['confidence'] for det in detections)
        st.metric("â­ ìµœê³  ì •í™•ë„", f"{max_conf:.1%}")

def process_single_image(uploaded_file, confidence_threshold, show_filename=False):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ê²°ê³¼ í‘œì‹œ"""
    
    if show_filename:
        st.write(f"**ğŸ“„ íŒŒì¼ëª…:** `{uploaded_file.name}`")
    
    file_size_mb = uploaded_file.size / (1024 * 1024)
    st.write(f"**ğŸ“Š íŒŒì¼ í¬ê¸°:** {file_size_mb:.2f} MB")
    
    if file_size_mb > 10:
        st.error("âŒ íŒŒì¼ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
        return
    
    # ì´ë¯¸ì§€ ë°”ì´íŠ¸ ì½ê¸°
    image_bytes = uploaded_file.read()
    
    with st.spinner("ğŸ” ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
        # ìºì‹± ì—†ëŠ” í•¨ìˆ˜ ì‚¬ìš©ìœ¼ë¡œ ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥
        annotated_image, detections, status = detect_objects_no_cache(image_bytes, confidence_threshold)
    
    if annotated_image is not None:
        # ê²°ê³¼ í‘œì‹œ
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€")
            original_image = Image.open(io.BytesIO(image_bytes))
            st.image(original_image, use_container_width=True)
        
        with col2:
            st.subheader(f"ğŸ¯ ê°ì§€ ê²°ê³¼ ({len(detections)}ê°œ ê°ì²´)")
            st.image(annotated_image, use_container_width=True)
        
        # í†µê³„ í‘œì‹œ
        if detections:
            st.markdown("---")
            st.subheader("ğŸ“Š ê°ì§€ í†µê³„")
            display_detection_stats(detections)
            
            # ìƒì„¸ ê²°ê³¼
            st.subheader("ğŸ“‹ ê°ì§€ëœ ê°ì²´ ìƒì„¸ ì •ë³´")
            
            # ì •í™•ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
            
            for i, detection in enumerate(sorted_detections, 1):
                with st.expander(f"ğŸ·ï¸ {i}. {detection['class_name']} ({detection['confidence']:.1%})"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**ì •í™•ë„:** {detection['confidence']:.3f}")
                        st.write(f"**í´ë˜ìŠ¤ ID:** {detection['class_id']}")
                    with col2:
                        width = detection['bbox'][2] - detection['bbox'][0]
                        height = detection['bbox'][3] - detection['bbox'][1]
                        st.write(f"**í¬ê¸°:** {width} Ã— {height} px")
                        st.write(f"**ë©´ì :** {detection['area']:,} pixels")
                    
                    st.write(f"**ìœ„ì¹˜:** ({detection['bbox'][0]}, {detection['bbox'][1]}) â†’ ({detection['bbox'][2]}, {detection['bbox'][3]})")
        else:
            st.warning("ğŸ¤” ê°ì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤. ì •í™•ë„ ì„ê³„ê°’ì„ ë‚®ì¶°ë³´ì„¸ìš”.")
    else:
        st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {status}")

def main():
    st.title("ğŸ´ ì”ë°˜ íƒì§€ê¸°")
    
    st.markdown("""
    ### ğŸ¤– YOLOv8 ê¸°ë°˜ ê°ì²´ ê°ì§€ ì‹œìŠ¤í…œ
    ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ë‹¤ì–‘í•œ ê°ì²´ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.
    """)
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        confidence_threshold = st.slider(
            "ğŸ¯ ì •í™•ë„ ì„ê³„ê°’",
            min_value=0.1,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="ì´ ê°’ë³´ë‹¤ ë†’ì€ ì •í™•ë„ì˜ ê°ì²´ë§Œ í‘œì‹œë©ë‹ˆë‹¤."
        )
        
        # ì¼ê´€ì„± ì„¤ì • ì¶”ê°€
        st.header("ğŸ”§ ì¼ê´€ì„± ì„¤ì •")
        
        use_consistent_inference = st.checkbox(
            "ì¼ê´€ëœ ì¶”ë¡  ëª¨ë“œ",
            value=True,
            help="Gradioì™€ ë™ì¼í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ìºì‹±ì„ ë¹„í™œì„±í™”í•˜ê³  ê³ ì •ëœ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )
        
        if use_consistent_inference:
            st.info("âœ… ì¼ê´€ëœ ì¶”ë¡  ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. Gradioì™€ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ìºì‹± ëª¨ë“œì…ë‹ˆë‹¤. ê²°ê³¼ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ ì—…ë¡œë”
    uploaded_files = st.file_uploader(
        "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        type=['jpg', 'jpeg', 'png', 'webp'],
        accept_multiple_files=True,
    )
    
    if uploaded_files:
        if len(uploaded_files) == 1:
            process_single_image(uploaded_files[0], confidence_threshold)
        else:
            st.success(f"ğŸ“ {len(uploaded_files)}ê°œì˜ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            for i, uploaded_file in enumerate(uploaded_files):
                st.markdown(f"## ğŸ“¸ ì´ë¯¸ì§€ {i+1}")
                process_single_image(uploaded_file, confidence_threshold, show_filename=True)
                st.markdown("---")
    else:
        st.info("ğŸ’¡ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ê°ì²´ ê°ì§€ë¥¼ ì‹œì‘í•˜ì„¸ìš”!")
        
        with st.expander("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ"):
            st.markdown("""
            ### Gradioì™€ ì¼ê´€ëœ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•œ ì„¤ì •:
            
            1. **ì¼ê´€ëœ ì¶”ë¡  ëª¨ë“œ í™œì„±í™”**: ì‚¬ì´ë“œë°”ì—ì„œ "ì¼ê´€ëœ ì¶”ë¡  ëª¨ë“œ" ì²´í¬ë°•ìŠ¤ë¥¼ í™œì„±í™”í•˜ì„¸ìš”
            2. **ë™ì¼í•œ íŒŒë¼ë¯¸í„° ì‚¬ìš©**: confidence thresholdë¥¼ Gradioì™€ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ì„¸ìš”
            3. **ë™ì¼í•œ ì´ë¯¸ì§€ ì‚¬ìš©**: ì™„ì „íˆ ê°™ì€ ì´ë¯¸ì§€ íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”
            
            ### ì£¼ìš” ì°¨ì´ì  í•´ê²°ì‚¬í•­:
            - âœ… ìºì‹± ë¹„í™œì„±í™”ë¡œ ë§¤ë²ˆ ìƒˆë¡œìš´ ì¶”ë¡ 
            - âœ… ì‹œë“œê°’ ê³ ì •ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼
            - âœ… ë™ì¼í•œ NMS ì„¤ì • ì ìš©
            - âœ… ë™ì¼í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë°©ì‹
            - âœ… ê³ ì •ëœ ìƒ‰ìƒ ë° ì‹œê°í™” ì„¤ì •
            """)

if __name__ == "__main__":
    main()
