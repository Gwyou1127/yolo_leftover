# YOLOv8 Streamlit ì•± ê°œì„ ëœ ì „ì²´ ì½”ë“œ (ë ˆì´ì•„ì›ƒ + progress bar + ì˜ìƒ ì¶”ë¡  í¬í•¨)

import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image
import io
import os
import torch
import tempfile
import time
import random

# ì„¤ì •
st.set_page_config(page_title="ğŸ´ ì”ë°˜ íƒì§€ê¸°", page_icon="ğŸ´", layout="wide")
os.environ['YOLO_VERBOSE'] = 'False'
warnings.filterwarnings('ignore')
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# YOLO ëª¨ë¸ ë¡œë“œ
@st.cache_resource(show_spinner=True)
def load_model():
    return YOLO("best.pt")

# ìƒ‰ìƒ ê³ ì •
def get_label_colors(model):
    random.seed(42)
    return [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in model.names]

# ì´ë¯¸ì§€ ê°ì§€ í•¨ìˆ˜
def detect_image(image_bytes, confidence):
    model = load_model()
    label_colors = get_label_colors(model)
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    img_array = np.array(image)
    results = model.predict(img_array, conf=confidence, iou=0.5)[0].cpu().numpy()

    detections = []
    for i, box in enumerate(results.boxes.xyxy):
        x1, y1, x2, y2 = map(int, box)
        cls = int(results.boxes.cls[i])
        conf = float(results.boxes.conf[i])
        label = model.names[cls]
        color = label_colors[cls]
        cv2.rectangle(img_array, (x1, y1), (x2, y2), color, 2)
        cv2.putText(img_array, f"{label} {conf:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        detections.append((label, conf))
    return Image.fromarray(img_array), detections

# ì˜ìƒ ê°ì§€ í•¨ìˆ˜
def detect_video(video_file, confidence):
    model = load_model()
    label_colors = get_label_colors(model)
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(video_file.read())
    cap = cv2.VideoCapture(tfile.name)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out_path = tempfile.mktemp(suffix=".mp4")
    width, height = int(cap.get(3)), int(cap.get(4))
    out = cv2.VideoWriter(out_path, fourcc, 20.0, (width, height))

    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    progress = st.progress(0)
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        results = model.predict(frame, conf=confidence, iou=0.5)[0]
        if results.boxes is not None:
            for i, box in enumerate(results.boxes.xyxy):
                x1, y1, x2, y2 = map(int, box)
                cls = int(results.boxes.cls[i])
                conf = float(results.boxes.conf[i])
                label = model.names[cls]
                color = label_colors[cls]
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        out.write(frame)
        frame_idx += 1
        progress.progress(min(frame_idx / total, 1.0))

    cap.release()
    out.release()
    return out_path

# UI
st.title("ğŸ´ ì”ë°˜ íƒì§€ê¸°")
tabs = st.tabs(["ğŸ“· ì´ë¯¸ì§€ ì¶”ë¡ ", "ğŸï¸ ì˜ìƒ ì¶”ë¡ "])

# ì´ë¯¸ì§€ íƒ­
with tabs[0]:
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
    conf = st.slider("ì •í™•ë„ ì„ê³„ê°’", 0.1, 1.0, 0.5, step=0.05)
    if uploaded_image:
        image_bytes = uploaded_image.read()
        st.image(image_bytes, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)
        with st.spinner("ê°ì§€ ì¤‘..."):
            result_img, detections = detect_image(image_bytes, conf)
        st.image(result_img, caption="ê°ì§€ ê²°ê³¼", use_column_width=True)
        st.write(f"ì´ ê°ì§€ ê°ì²´ ìˆ˜: {len(detections)}")

# ì˜ìƒ íƒ­
with tabs[1]:
    uploaded_video = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "mov", "avi"])
    conf_v = st.slider("ì •í™•ë„ ì„ê³„ê°’", 0.1, 1.0, 0.5, step=0.05, key="video_conf")
    if uploaded_video:
        st.video(uploaded_video, format="video/mp4")
        with st.spinner("ì˜ìƒ ì²˜ë¦¬ ì¤‘... ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤"):
            out_path = detect_video(uploaded_video, conf_v)
        st.success("ğŸ‰ ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ!")
        st.video(out_path)
        with open(out_path, "rb") as f:
            st.download_button("ğŸ“¥ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ", f, file_name="output.mp4")
